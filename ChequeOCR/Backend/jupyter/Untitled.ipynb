{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b52ccfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f752614e",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\thresh.cpp:1645: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'cv::adaptiveThreshold'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m Image\u001b[38;5;241m.\u001b[39mfromarray(image)\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# masking hindi letters from cheque\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# img_grey_arr = np.array(img_grey)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# img_grey_arr[259:299,339:336] =(0, 0)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# img_grey = Image.fromarray(img_grey_arr)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Image.fromarray(img_grey).show()\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m new_img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madaptiveThreshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mADAPTIVE_THRESH_GAUSSIAN_C\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTHRESH_BINARY\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m55\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m pytesseract\u001b[38;5;241m.\u001b[39mpytesseract\u001b[38;5;241m.\u001b[39mtesseract_cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpirat\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAppData\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLocal\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTesseract-OCR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtesseract.exe\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     23\u001b[0m text \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_string(image, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\thresh.cpp:1645: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'cv::adaptiveThreshold'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d2fc635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Removing backgroung image from hdfc cheque\n",
    "\n",
    "o_img= cv2.imread(\"o_hdfc_e2.jpg\", flags = cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "o_img\n",
    "\n",
    "# grey_img = cv2.cvtColor(o_img, cv2.COLOR_BGR2GRAY)\n",
    "# # Image.fromarray(grey_img).show()\n",
    "\n",
    "# _, alpha = cv2.threshold(o_img, 255, 200, cv2.THRESH_BINARY)\n",
    "\n",
    "# cv2.imshow(\"Threshold Image\",o_img)\n",
    "# b, g, r = cv2.split(o_img)\n",
    "# rgba = [b, g, r, alpha]\n",
    "# dst = cv2.merge(rgba, 2)\n",
    "# cv2.imwrite(\"hdfc_b.jpg\", dst)\n",
    "# image1 = cv2.imread(\"hdfc_b.jpg\")\n",
    "\n",
    "# Image.fromarray(image1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7217dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
